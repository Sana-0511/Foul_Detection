{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ba75b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tackle Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd9a004d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.15.0-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.15.0\n",
      "  Using cached tensorflow_intel-2.15.0-cp39-cp39-win_amd64.whl (300.8 MB)\n",
      "Collecting keras<2.16,>=2.15.0\n",
      "  Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Using cached gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.26.1)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.60.0-cp39-cp39-win_amd64.whl (3.7 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting tensorboard<2.16,>=2.15\n",
      "  Using cached tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.26.2-py2.py3-none-any.whl (186 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.3)\n",
      "Collecting google-auth-oauthlib<2,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.15.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: keras, grpcio, google-pasta, gast, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 gast-0.5.4 google-auth-2.26.2 google-auth-oauthlib-1.2.0 google-pasta-0.2.0 grpcio-1.60.0 keras-2.15.0 requests-oauthlib-1.3.1 tensorboard-2.15.1 tensorflow-2.15.0 tensorflow-intel-2.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "587687cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.26.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.26.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.15.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\nehaa\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e2a8b6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.15.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\nehaa\\anaconda3\\lib\\site-packages\n",
      "Requires: tensorflow-intel\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73eb3634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow                    2.15.0\n",
      "tensorflow-estimator          2.15.0\n",
      "tensorflow-intel              2.15.0\n",
      "tensorflow-io-gcs-filesystem  0.31.0\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "084cbf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "287fb61c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import models,layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d92581e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the dataset\n",
    "def load_dataset(data_dir, target_size=(224, 224)):\n",
    "    X, y = [], []\n",
    "\n",
    "    for label, class_dir in enumerate(['tackles', 'non_tackles']):\n",
    "        class_path = os.path.join(data_dir, class_dir)\n",
    "\n",
    "        if not os.path.exists(class_path):\n",
    "            print(f\"Warning: Directory '{class_dir}' not found in {data_dir}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        for video_dir in os.listdir(class_path):\n",
    "            video_path = os.path.join(class_path, video_dir)\n",
    "\n",
    "            if not os.path.exists(video_path):\n",
    "                print(f\"Warning: Video directory '{video_dir}' not found in {class_path}. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            for frame_file in os.listdir(video_path):\n",
    "                frame_path = os.path.join(video_path, frame_file)\n",
    "\n",
    "                # Load and preprocess the frame\n",
    "                frame = load_img(frame_path, target_size=target_size)\n",
    "                frame = img_to_array(frame) / 255.0\n",
    "\n",
    "                X.append(frame)\n",
    "                y.append(class_dir)\n",
    "\n",
    "    if not X or not y:\n",
    "        print(\"Error: No data found in the specified directory. Please check your dataset structure.\")\n",
    "        return None, None\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Convert labels to numerical format\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    y = to_categorical(y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Create a ResNet50 model\n",
    "def create_resnet50_model(input_shape, num_classes):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Freezing  the pre-trained layers( to avoid training them during next steps)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Replace 'path/to/your/dataset' with the actual path to your dataset\n",
    "data_dir = r\"C:\\Users\\nehaa\\Downloads\\frames of the dataset\"\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "X, y = load_dataset(data_dir)\n",
    "\n",
    "# Check if the dataset is loaded successfully\n",
    "if X is None or y is None:\n",
    "    exit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "212c943f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nehaa\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\nehaa\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\nehaa\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "23/23 [==============================] - 63s 2s/step - loss: 0.6695 - accuracy: 0.6747 - val_loss: 0.5389 - val_accuracy: 0.7514\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.5591 - accuracy: 0.7355 - val_loss: 0.4952 - val_accuracy: 0.7514\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 54s 2s/step - loss: 0.5164 - accuracy: 0.7511 - val_loss: 0.4477 - val_accuracy: 0.8644\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 52s 2s/step - loss: 0.4676 - accuracy: 0.7992 - val_loss: 0.4194 - val_accuracy: 0.7514\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 54s 2s/step - loss: 0.4491 - accuracy: 0.7949 - val_loss: 0.3669 - val_accuracy: 0.8983\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 56s 2s/step - loss: 0.4159 - accuracy: 0.8246 - val_loss: 0.3412 - val_accuracy: 0.8983\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.3674 - accuracy: 0.8529 - val_loss: 0.3026 - val_accuracy: 0.8983\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.3514 - accuracy: 0.8557 - val_loss: 0.2756 - val_accuracy: 0.9096\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 230s 10s/step - loss: 0.3526 - accuracy: 0.8571 - val_loss: 0.2671 - val_accuracy: 0.9096\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 54s 2s/step - loss: 0.3321 - accuracy: 0.8557 - val_loss: 0.2550 - val_accuracy: 0.9040\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2940 - accuracy: 0.8713 - val_loss: 0.2372 - val_accuracy: 0.9040\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.3226 - accuracy: 0.8670 - val_loss: 0.2327 - val_accuracy: 0.8870\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 54s 2s/step - loss: 0.2977 - accuracy: 0.8713 - val_loss: 0.2521 - val_accuracy: 0.8927\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 52s 2s/step - loss: 0.2757 - accuracy: 0.8854 - val_loss: 0.3085 - val_accuracy: 0.8927\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.3029 - accuracy: 0.8699 - val_loss: 0.2191 - val_accuracy: 0.8983\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2790 - accuracy: 0.8685 - val_loss: 0.2141 - val_accuracy: 0.9040\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 54s 2s/step - loss: 0.2891 - accuracy: 0.8628 - val_loss: 0.2200 - val_accuracy: 0.8927\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 54s 2s/step - loss: 0.2834 - accuracy: 0.8840 - val_loss: 0.2101 - val_accuracy: 0.9096\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2997 - accuracy: 0.8769 - val_loss: 0.2244 - val_accuracy: 0.9153\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2720 - accuracy: 0.8897 - val_loss: 0.2064 - val_accuracy: 0.9040\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2542 - accuracy: 0.8925 - val_loss: 0.1984 - val_accuracy: 0.9040\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2431 - accuracy: 0.8911 - val_loss: 0.1949 - val_accuracy: 0.8983\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2441 - accuracy: 0.8953 - val_loss: 0.2063 - val_accuracy: 0.9153\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2580 - accuracy: 0.8868 - val_loss: 0.1987 - val_accuracy: 0.8983\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2555 - accuracy: 0.8868 - val_loss: 0.1951 - val_accuracy: 0.9153\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2415 - accuracy: 0.8911 - val_loss: 0.2001 - val_accuracy: 0.8983\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2491 - accuracy: 0.8755 - val_loss: 0.1867 - val_accuracy: 0.8983\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2628 - accuracy: 0.8784 - val_loss: 0.1883 - val_accuracy: 0.9153\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2463 - accuracy: 0.8826 - val_loss: 0.1837 - val_accuracy: 0.9040\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 54s 2s/step - loss: 0.2223 - accuracy: 0.9038 - val_loss: 0.2010 - val_accuracy: 0.9040\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2973 - accuracy: 0.8713 - val_loss: 0.1848 - val_accuracy: 0.9040\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 54s 2s/step - loss: 0.2435 - accuracy: 0.8868 - val_loss: 0.1799 - val_accuracy: 0.9153\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2382 - accuracy: 0.8897 - val_loss: 0.2050 - val_accuracy: 0.9040\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2336 - accuracy: 0.8939 - val_loss: 0.1749 - val_accuracy: 0.9040\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 54s 2s/step - loss: 0.2271 - accuracy: 0.9052 - val_loss: 0.1723 - val_accuracy: 0.9153\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2016 - accuracy: 0.9109 - val_loss: 0.1685 - val_accuracy: 0.9153\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2147 - accuracy: 0.8967 - val_loss: 0.1669 - val_accuracy: 0.9153\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2338 - accuracy: 0.8967 - val_loss: 0.1665 - val_accuracy: 0.9209\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2317 - accuracy: 0.8996 - val_loss: 0.1679 - val_accuracy: 0.9153\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2049 - accuracy: 0.9081 - val_loss: 0.1740 - val_accuracy: 0.9040\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 56s 2s/step - loss: 0.1987 - accuracy: 0.9095 - val_loss: 0.1950 - val_accuracy: 0.9040\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2436 - accuracy: 0.8925 - val_loss: 0.1656 - val_accuracy: 0.9153\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2141 - accuracy: 0.9010 - val_loss: 0.1821 - val_accuracy: 0.9209\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 54s 2s/step - loss: 0.2061 - accuracy: 0.9222 - val_loss: 0.1638 - val_accuracy: 0.9209\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2110 - accuracy: 0.9038 - val_loss: 0.1821 - val_accuracy: 0.9096\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 54s 2s/step - loss: 0.1973 - accuracy: 0.9066 - val_loss: 0.1738 - val_accuracy: 0.9209\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2083 - accuracy: 0.9081 - val_loss: 0.1554 - val_accuracy: 0.9209\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2130 - accuracy: 0.8996 - val_loss: 0.1640 - val_accuracy: 0.9209\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2133 - accuracy: 0.9109 - val_loss: 0.1567 - val_accuracy: 0.9209\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.2205 - accuracy: 0.9066 - val_loss: 0.1550 - val_accuracy: 0.9153\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.1461 - accuracy: 0.9369\n",
      "Test accuracy: 0.9369369149208069\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a ResNet50 model\n",
    "input_shape = X_train[0].shape\n",
    "num_classes = 2  # Adjust based on your task (tackle and non-tackle)\n",
    "model = create_resnet50_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c45b2dfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\nehaa\\Downloads\\Real-time Event recognition\\saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\nehaa\\Downloads\\Real-time Event recognition\\saved_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model to a file using the SavedModel format\n",
    "tf.saved_model.save(model, r\"C:\\Users\\nehaa\\Downloads\\Real-time Event recognition\\saved_model\")\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = tf.saved_model.load(r\"C:\\Users\\nehaa\\Downloads\\Real-time Event recognition\\saved_model\")\n",
    "\n",
    "# Now you can use loaded_model for predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "881417d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfb3fb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n",
      "Prediction Keys: dict_keys(['dense_1'])\n",
      "No tackle detected.\n"
     ]
    }
   ],
   "source": [
    "# Get the signature of the model(i.e inputs and outputs of the model)\n",
    "signature = loaded_model.signatures[\"serving_default\"]\n",
    "\n",
    "# Replace 'path/to/your/random_video.mp4' with the actual path to your video\n",
    "random_video_path = r\"C:\\Users\\nehaa\\Downloads\\dataset for soccer\\tackles\\1.mp4\"\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture(random_video_path)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize the frame to match the input size of your model\n",
    "    frame = cv2.resize(frame, (224, 224))\n",
    "\n",
    "    # Preprocess the frame\n",
    "    frame = frame / 255.0  # Normalize to [0, 1]\n",
    "    frame = np.expand_dims(frame, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Make a prediction using the model\n",
    "    prediction = signature(tf.constant(frame, dtype=tf.float32))\n",
    "    \n",
    "    # Print the keys of the prediction dictionary\n",
    "    print(\"Prediction Keys:\", prediction.keys())\n",
    "\n",
    "    # Assuming class 0 is 'tackle'\n",
    "    output_key='dense_1'\n",
    "    if prediction['dense_1'][0, 0] > 0.5:\n",
    "        print(\"Tackle detected!\")\n",
    "    else:\n",
    "        print(\"No tackle detected.\")\n",
    "\n",
    "    # Display the frame (optional)\n",
    "    cv2.imshow('Frame', frame[0])\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8b5ede9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pafy\n",
      "  Downloading pafy-0.5.5-py2.py3-none-any.whl (35 kB)\n",
      "Installing collected packages: pafy\n",
      "Successfully installed pafy-0.5.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pafy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d053d9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube_dlNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading youtube_dl-2021.12.17-py2.py3-none-any.whl (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 61.5 kB/s eta 0:00:00\n",
      "Installing collected packages: youtube_dl\n",
      "Successfully installed youtube_dl-2021.12.17\n"
     ]
    }
   ],
   "source": [
    "pip install youtube_dl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be1cdeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytube\n",
      "  Using cached pytube-15.0.0-py3-none-any.whl (57 kB)\n",
      "Installing collected packages: pytube\n",
      "Successfully installed pytube-15.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytube\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "004af291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import subprocess\n",
    "\n",
    "# pre-trained ResNet50 model\n",
    "saved_model_path = r\"C:\\Users\\nehaa\\Downloads\\Real-time Event recognition\\saved_model\" \n",
    "loaded_model = tf.saved_model.load(saved_model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d3cc699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3d62266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tackle detected! Event started at 1705563773.1554792\n",
      "Event duration: 0 minutes and 37.13 seconds\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from pytube import YouTube\n",
    "\n",
    "def download_youtube_video(video_url, output_path='temp_video.mp4'):\n",
    "    try:\n",
    "        yt = YouTube(video_url)\n",
    "        ys = yt.streams.get_highest_resolution()\n",
    "        ys.download(output_path)\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_youtube_frames(video_url, num_frames=300):\n",
    "    try:\n",
    "        yt = YouTube(video_url)\n",
    "        ys = yt.streams.get_highest_resolution()\n",
    "        cap = cv2.VideoCapture(ys.url)\n",
    "        frames = []\n",
    "\n",
    "        for _ in range(num_frames):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frames.append(frame)\n",
    "\n",
    "        cap.release()\n",
    "        return frames\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def detect_tackle(frame):\n",
    "    # Preprocess the input frame to match the model's expected input format\n",
    "    frame = cv2.resize(frame, (224, 224))\n",
    "    frame = frame / 255.0  # Normalize to [0, 1]\n",
    "    frame = np.expand_dims(frame, axis=0)  # Add batch dimension\n",
    "    frame = tf.convert_to_tensor(frame, dtype=tf.float32)  # Convert to TensorFlow tensor\n",
    "\n",
    "    # Using the loaded model for prediction\n",
    "    prediction = loaded_model(frame)\n",
    "\n",
    "    return np.argmax(prediction) == 0  # Assuming class 0 is 'tackle'\n",
    "\n",
    "def process_video_stream(video_source):\n",
    "    # Get frames directly from the YouTube video\n",
    "    frames = get_youtube_frames(video_source)\n",
    "\n",
    "    if frames is None:\n",
    "        print(\"Error: Could not retrieve frames from the YouTube video.\")\n",
    "        return\n",
    "\n",
    "    # Variable to store the start time of the event\n",
    "    event_start_time = None\n",
    "\n",
    "    for frame in frames:\n",
    "        # Perform tackle detection\n",
    "        is_tackle = detect_tackle(frame)\n",
    "\n",
    "        # If a tackle is detected, trigger the event\n",
    "        if is_tackle:\n",
    "            if event_start_time is None:\n",
    "                event_start_time = time.time()\n",
    "                print(f\"Tackle detected! Event started at {event_start_time}\")\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Soccer Match', frame)\n",
    "\n",
    "        # Check for user input to exit the loop\n",
    "        key = cv2.waitKey(1)\n",
    "        if key & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Close the display window\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # If a tackle was detected, print the exact time\n",
    "    if event_start_time is not None:\n",
    "        event_end_time = time.time()\n",
    "        elapsed_time = event_end_time - event_start_time\n",
    "\n",
    "        # Convert elapsed time to minutes and seconds\n",
    "        minutes, seconds = divmod(elapsed_time, 60)\n",
    "        print(f\"Event duration: {int(minutes)} minutes and {seconds:.2f} seconds\")\n",
    "\n",
    "# Replace 'your_video_source' with the actual YouTube video URL\n",
    "process_video_stream(r\"https://www.youtube.com/watch?v=wRAUnwpRfgk\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb3a369",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
