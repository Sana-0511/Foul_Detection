{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2999734,"sourceType":"datasetVersion","datasetId":1826242},{"sourceId":5693340,"sourceType":"datasetVersion","datasetId":3273568},{"sourceId":7176183,"sourceType":"datasetVersion","datasetId":4146969},{"sourceId":7381629,"sourceType":"datasetVersion","datasetId":4289893},{"sourceId":7388474,"sourceType":"datasetVersion","datasetId":4294753}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-12T11:18:40.321272Z","iopub.execute_input":"2024-01-12T11:18:40.321547Z","iopub.status.idle":"2024-01-12T11:18:53.960367Z","shell.execute_reply.started":"2024-01-12T11:18:40.321522Z","shell.execute_reply":"2024-01-12T11:18:53.959501Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load and preprocess images\ndef load_images_from_folder(folder):\n    images = []\n    for filename in os.listdir(folder):\n        img = cv2.imread(os.path.join(folder, filename))\n        if img is not None:\n            img = cv2.resize(img, (224, 224))  # Resize images to a common size\n            images.append(img)\n    return images","metadata":{"execution":{"iopub.status.busy":"2024-01-12T11:19:05.972578Z","iopub.execute_input":"2024-01-12T11:19:05.973618Z","iopub.status.idle":"2024-01-12T11:19:05.979231Z","shell.execute_reply.started":"2024-01-12T11:19:05.973583Z","shell.execute_reply":"2024-01-12T11:19:05.978220Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Load and preprocess data\nfoul_images = load_images_from_folder('/kaggle/input/op-dataset/OP_Dataset/Train/foul')\nnon_foul_images = load_images_from_folder('/kaggle/input/op-dataset/OP_Dataset/Train/non_foul')\n\n# Create labels (1 for foul, 0 for non-foul)\nfoul_labels = np.ones(len(foul_images))\nnon_foul_labels = np.zeros(len(non_foul_images))\n\n# Combine data and labels\ndata = np.array(foul_images + non_foul_images)\nlabels = np.concatenate((foul_labels, non_foul_labels))\n\nval_foul_images = load_images_from_folder(\"/kaggle/input/op-dataset/OP_Dataset/Valid/foul\")\nval_non_foul_images = load_images_from_folder(\"/kaggle/input/op-dataset/OP_Dataset/Valid/non_foul\")\n\nval_foul_labels = np.ones(len(val_foul_images))\nval_non_foul_labels = np.zeros(len(val_non_foul_images))\n\nval_data = np.array(val_foul_images + val_non_foul_images)\nval_labels = np.concatenate((val_foul_labels, val_non_foul_labels))\n\n\n# Split the data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-01-12T11:19:08.414690Z","iopub.execute_input":"2024-01-12T11:19:08.415070Z","iopub.status.idle":"2024-01-12T11:19:29.432809Z","shell.execute_reply.started":"2024-01-12T11:19:08.415039Z","shell.execute_reply":"2024-01-12T11:19:29.431945Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint\n\n# Data augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=30,  # Increased rotation range\n    width_shift_range=0.3,  # Increased width shift range\n    height_shift_range=0.3,  # Increased height shift range\n    shear_range=0.3,  # Increased shear range\n    zoom_range=0.3,  # Increased zoom range\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Assuming your labels include both classification labels and bounding box coordinates\ntrain_generator = datagen.flow(X_train, y_train, batch_size=32)\n\n\ninput_shape = (224, 224, 3)\nnum_classes = 1  # Binary classification for foul detection\n\n# Build the EfficientNetB0 model\nbase_model = tf.keras.applications.EfficientNetB0(input_shape=input_shape, include_top=False, weights='imagenet')\n\n# Unfreeze some layers for fine-tuning\nfor layer in base_model.layers[-20:]:\n    layer.trainable = True\n\n# Feature extraction\nx = base_model.output\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dense(512, activation='relu')(x)\nx = tf.keras.layers.Dropout(0.5)(x)\nx = tf.keras.layers.Dense(256, activation='relu')(x)\nx = tf.keras.layers.Dropout(0.5)(x)\n\n# Classification head\nclassification_head = tf.keras.layers.Dense(num_classes, activation='sigmoid', name='classification')(x)\n\n# Build the model\nmodel = tf.keras.Model(inputs=base_model.input, outputs=classification_head)\n\n# Compile the model\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Learning Rate Scheduler\ndef lr_scheduler(epoch, lr):\n    if epoch % 10 == 0 and epoch > 0:\n        lr = lr * 0.9\n    return lr\n\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n\n# Train the model\nhistory = model.fit(train_generator,\n                    epochs=100,\n                    validation_data=(X_val, y_val),\n                    callbacks=[lr_schedule])\n\n# Evaluate the model on the validation set\nval_loss, val_accuracy = model.evaluate(X_val, y_val)\nprint(\"Validation Accuracy:\", val_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-01-12T11:19:29.434812Z","iopub.execute_input":"2024-01-12T11:19:29.435474Z","iopub.status.idle":"2024-01-12T11:42:31.704945Z","shell.execute_reply.started":"2024-01-12T11:19:29.435435Z","shell.execute_reply":"2024-01-12T11:42:31.703995Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n16705208/16705208 [==============================] - 0s 0us/step\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"2024-01-12 11:19:49.659860: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"31/31 [==============================] - 58s 509ms/step - loss: 0.7145 - accuracy: 0.5254 - val_loss: 0.6581 - val_accuracy: 0.6266 - lr: 1.0000e-04\nEpoch 2/100\n31/31 [==============================] - 13s 426ms/step - loss: 0.6900 - accuracy: 0.5576 - val_loss: 0.6436 - val_accuracy: 0.6763 - lr: 1.0000e-04\nEpoch 3/100\n31/31 [==============================] - 13s 422ms/step - loss: 0.6685 - accuracy: 0.5826 - val_loss: 0.6211 - val_accuracy: 0.6929 - lr: 1.0000e-04\nEpoch 4/100\n31/31 [==============================] - 13s 410ms/step - loss: 0.6370 - accuracy: 0.6449 - val_loss: 0.5968 - val_accuracy: 0.7303 - lr: 1.0000e-04\nEpoch 5/100\n31/31 [==============================] - 13s 423ms/step - loss: 0.5960 - accuracy: 0.6791 - val_loss: 0.5616 - val_accuracy: 0.7344 - lr: 1.0000e-04\nEpoch 6/100\n31/31 [==============================] - 13s 418ms/step - loss: 0.5615 - accuracy: 0.7155 - val_loss: 0.5349 - val_accuracy: 0.7386 - lr: 1.0000e-04\nEpoch 7/100\n31/31 [==============================] - 13s 420ms/step - loss: 0.5192 - accuracy: 0.7508 - val_loss: 0.4876 - val_accuracy: 0.7801 - lr: 1.0000e-04\nEpoch 8/100\n31/31 [==============================] - 13s 413ms/step - loss: 0.4670 - accuracy: 0.7653 - val_loss: 0.4843 - val_accuracy: 0.7718 - lr: 1.0000e-04\nEpoch 9/100\n31/31 [==============================] - 13s 419ms/step - loss: 0.4447 - accuracy: 0.7965 - val_loss: 0.4359 - val_accuracy: 0.8091 - lr: 1.0000e-04\nEpoch 10/100\n31/31 [==============================] - 13s 424ms/step - loss: 0.3731 - accuracy: 0.8370 - val_loss: 0.4332 - val_accuracy: 0.8091 - lr: 1.0000e-04\nEpoch 11/100\n31/31 [==============================] - 13s 418ms/step - loss: 0.3515 - accuracy: 0.8390 - val_loss: 0.4100 - val_accuracy: 0.8133 - lr: 9.0000e-05\nEpoch 12/100\n31/31 [==============================] - 13s 418ms/step - loss: 0.3056 - accuracy: 0.8629 - val_loss: 0.5833 - val_accuracy: 0.7593 - lr: 9.0000e-05\nEpoch 13/100\n31/31 [==============================] - 13s 414ms/step - loss: 0.2910 - accuracy: 0.8754 - val_loss: 0.6047 - val_accuracy: 0.7510 - lr: 9.0000e-05\nEpoch 14/100\n31/31 [==============================] - 13s 419ms/step - loss: 0.2922 - accuracy: 0.8775 - val_loss: 0.5770 - val_accuracy: 0.7593 - lr: 9.0000e-05\nEpoch 15/100\n31/31 [==============================] - 13s 420ms/step - loss: 0.2496 - accuracy: 0.8962 - val_loss: 0.3899 - val_accuracy: 0.8631 - lr: 9.0000e-05\nEpoch 16/100\n31/31 [==============================] - 13s 410ms/step - loss: 0.2178 - accuracy: 0.9180 - val_loss: 0.4231 - val_accuracy: 0.8465 - lr: 9.0000e-05\nEpoch 17/100\n31/31 [==============================] - 13s 424ms/step - loss: 0.1988 - accuracy: 0.9169 - val_loss: 0.4125 - val_accuracy: 0.8423 - lr: 9.0000e-05\nEpoch 18/100\n31/31 [==============================] - 13s 412ms/step - loss: 0.2161 - accuracy: 0.9159 - val_loss: 0.4792 - val_accuracy: 0.8299 - lr: 9.0000e-05\nEpoch 19/100\n31/31 [==============================] - 13s 425ms/step - loss: 0.1884 - accuracy: 0.9211 - val_loss: 0.4915 - val_accuracy: 0.8174 - lr: 9.0000e-05\nEpoch 20/100\n31/31 [==============================] - 13s 418ms/step - loss: 0.1598 - accuracy: 0.9418 - val_loss: 0.4317 - val_accuracy: 0.8465 - lr: 9.0000e-05\nEpoch 21/100\n31/31 [==============================] - 13s 420ms/step - loss: 0.1626 - accuracy: 0.9450 - val_loss: 0.4418 - val_accuracy: 0.8382 - lr: 8.1000e-05\nEpoch 22/100\n31/31 [==============================] - 13s 418ms/step - loss: 0.1228 - accuracy: 0.9533 - val_loss: 0.4424 - val_accuracy: 0.8714 - lr: 8.1000e-05\nEpoch 23/100\n31/31 [==============================] - 13s 417ms/step - loss: 0.1407 - accuracy: 0.9512 - val_loss: 0.3574 - val_accuracy: 0.8797 - lr: 8.1000e-05\nEpoch 24/100\n31/31 [==============================] - 14s 428ms/step - loss: 0.1354 - accuracy: 0.9418 - val_loss: 0.4334 - val_accuracy: 0.8423 - lr: 8.1000e-05\nEpoch 25/100\n31/31 [==============================] - 13s 420ms/step - loss: 0.1061 - accuracy: 0.9647 - val_loss: 0.5137 - val_accuracy: 0.8216 - lr: 8.1000e-05\nEpoch 26/100\n31/31 [==============================] - 13s 420ms/step - loss: 0.1422 - accuracy: 0.9481 - val_loss: 0.4462 - val_accuracy: 0.8589 - lr: 8.1000e-05\nEpoch 27/100\n31/31 [==============================] - 13s 423ms/step - loss: 0.1011 - accuracy: 0.9647 - val_loss: 0.4631 - val_accuracy: 0.8506 - lr: 8.1000e-05\nEpoch 28/100\n31/31 [==============================] - 13s 427ms/step - loss: 0.0938 - accuracy: 0.9699 - val_loss: 0.4968 - val_accuracy: 0.8382 - lr: 8.1000e-05\nEpoch 29/100\n31/31 [==============================] - 13s 418ms/step - loss: 0.0941 - accuracy: 0.9626 - val_loss: 0.4345 - val_accuracy: 0.8631 - lr: 8.1000e-05\nEpoch 30/100\n31/31 [==============================] - 13s 409ms/step - loss: 0.1323 - accuracy: 0.9522 - val_loss: 0.4493 - val_accuracy: 0.8506 - lr: 8.1000e-05\nEpoch 31/100\n31/31 [==============================] - 13s 418ms/step - loss: 0.1047 - accuracy: 0.9668 - val_loss: 0.4470 - val_accuracy: 0.8548 - lr: 7.2900e-05\nEpoch 32/100\n31/31 [==============================] - 13s 422ms/step - loss: 0.1150 - accuracy: 0.9605 - val_loss: 0.4211 - val_accuracy: 0.8880 - lr: 7.2900e-05\nEpoch 33/100\n31/31 [==============================] - 14s 429ms/step - loss: 0.0949 - accuracy: 0.9699 - val_loss: 0.4117 - val_accuracy: 0.8755 - lr: 7.2900e-05\nEpoch 34/100\n31/31 [==============================] - 13s 419ms/step - loss: 0.0963 - accuracy: 0.9647 - val_loss: 0.4115 - val_accuracy: 0.8921 - lr: 7.2900e-05\nEpoch 35/100\n31/31 [==============================] - 13s 418ms/step - loss: 0.1014 - accuracy: 0.9657 - val_loss: 0.4397 - val_accuracy: 0.8631 - lr: 7.2900e-05\nEpoch 36/100\n31/31 [==============================] - 13s 426ms/step - loss: 0.0797 - accuracy: 0.9720 - val_loss: 0.4102 - val_accuracy: 0.8880 - lr: 7.2900e-05\nEpoch 37/100\n31/31 [==============================] - 13s 422ms/step - loss: 0.0680 - accuracy: 0.9761 - val_loss: 0.4010 - val_accuracy: 0.8963 - lr: 7.2900e-05\nEpoch 38/100\n31/31 [==============================] - 14s 432ms/step - loss: 0.0623 - accuracy: 0.9792 - val_loss: 0.4312 - val_accuracy: 0.8838 - lr: 7.2900e-05\nEpoch 39/100\n31/31 [==============================] - 13s 413ms/step - loss: 0.0583 - accuracy: 0.9792 - val_loss: 0.4052 - val_accuracy: 0.9004 - lr: 7.2900e-05\nEpoch 40/100\n31/31 [==============================] - 13s 421ms/step - loss: 0.0603 - accuracy: 0.9803 - val_loss: 0.4711 - val_accuracy: 0.8672 - lr: 7.2900e-05\nEpoch 41/100\n31/31 [==============================] - 13s 418ms/step - loss: 0.0756 - accuracy: 0.9751 - val_loss: 0.4857 - val_accuracy: 0.8589 - lr: 6.5610e-05\nEpoch 42/100\n31/31 [==============================] - 13s 416ms/step - loss: 0.0724 - accuracy: 0.9761 - val_loss: 0.4936 - val_accuracy: 0.8631 - lr: 6.5610e-05\nEpoch 43/100\n31/31 [==============================] - 13s 424ms/step - loss: 0.0714 - accuracy: 0.9761 - val_loss: 0.5178 - val_accuracy: 0.8589 - lr: 6.5610e-05\nEpoch 44/100\n31/31 [==============================] - 13s 408ms/step - loss: 0.0848 - accuracy: 0.9720 - val_loss: 0.4862 - val_accuracy: 0.8465 - lr: 6.5610e-05\nEpoch 45/100\n31/31 [==============================] - 13s 428ms/step - loss: 0.0672 - accuracy: 0.9792 - val_loss: 0.4847 - val_accuracy: 0.8589 - lr: 6.5610e-05\nEpoch 46/100\n31/31 [==============================] - 13s 416ms/step - loss: 0.0874 - accuracy: 0.9657 - val_loss: 0.4899 - val_accuracy: 0.8548 - lr: 6.5610e-05\nEpoch 47/100\n31/31 [==============================] - 13s 425ms/step - loss: 0.0734 - accuracy: 0.9688 - val_loss: 0.4360 - val_accuracy: 0.8589 - lr: 6.5610e-05\nEpoch 48/100\n31/31 [==============================] - 13s 422ms/step - loss: 0.0679 - accuracy: 0.9740 - val_loss: 0.4263 - val_accuracy: 0.8714 - lr: 6.5610e-05\nEpoch 49/100\n31/31 [==============================] - 13s 420ms/step - loss: 0.0764 - accuracy: 0.9720 - val_loss: 0.4536 - val_accuracy: 0.8714 - lr: 6.5610e-05\nEpoch 50/100\n31/31 [==============================] - 13s 424ms/step - loss: 0.0443 - accuracy: 0.9855 - val_loss: 0.5460 - val_accuracy: 0.8465 - lr: 6.5610e-05\nEpoch 51/100\n31/31 [==============================] - 13s 423ms/step - loss: 0.0519 - accuracy: 0.9834 - val_loss: 0.4469 - val_accuracy: 0.8838 - lr: 5.9049e-05\nEpoch 52/100\n31/31 [==============================] - 13s 424ms/step - loss: 0.0513 - accuracy: 0.9813 - val_loss: 0.4563 - val_accuracy: 0.8631 - lr: 5.9049e-05\nEpoch 53/100\n31/31 [==============================] - 13s 416ms/step - loss: 0.0418 - accuracy: 0.9865 - val_loss: 0.4481 - val_accuracy: 0.8714 - lr: 5.9049e-05\nEpoch 54/100\n31/31 [==============================] - 13s 417ms/step - loss: 0.0675 - accuracy: 0.9720 - val_loss: 0.4394 - val_accuracy: 0.8838 - lr: 5.9049e-05\nEpoch 55/100\n31/31 [==============================] - 13s 422ms/step - loss: 0.0397 - accuracy: 0.9865 - val_loss: 0.4312 - val_accuracy: 0.8880 - lr: 5.9049e-05\nEpoch 56/100\n31/31 [==============================] - 13s 419ms/step - loss: 0.0496 - accuracy: 0.9855 - val_loss: 0.4020 - val_accuracy: 0.8880 - lr: 5.9049e-05\nEpoch 57/100\n31/31 [==============================] - 13s 420ms/step - loss: 0.0334 - accuracy: 0.9865 - val_loss: 0.4128 - val_accuracy: 0.8880 - lr: 5.9049e-05\nEpoch 58/100\n31/31 [==============================] - 13s 413ms/step - loss: 0.0448 - accuracy: 0.9855 - val_loss: 0.4264 - val_accuracy: 0.8838 - lr: 5.9049e-05\nEpoch 59/100\n31/31 [==============================] - 14s 432ms/step - loss: 0.0478 - accuracy: 0.9855 - val_loss: 0.3967 - val_accuracy: 0.9046 - lr: 5.9049e-05\nEpoch 60/100\n31/31 [==============================] - 13s 415ms/step - loss: 0.0408 - accuracy: 0.9834 - val_loss: 0.4005 - val_accuracy: 0.9046 - lr: 5.9049e-05\nEpoch 61/100\n31/31 [==============================] - 13s 427ms/step - loss: 0.0496 - accuracy: 0.9792 - val_loss: 0.3794 - val_accuracy: 0.9046 - lr: 5.3144e-05\nEpoch 62/100\n31/31 [==============================] - 13s 414ms/step - loss: 0.0689 - accuracy: 0.9761 - val_loss: 0.4060 - val_accuracy: 0.8838 - lr: 5.3144e-05\nEpoch 63/100\n31/31 [==============================] - 13s 425ms/step - loss: 0.0514 - accuracy: 0.9834 - val_loss: 0.4443 - val_accuracy: 0.8714 - lr: 5.3144e-05\nEpoch 64/100\n31/31 [==============================] - 14s 442ms/step - loss: 0.0498 - accuracy: 0.9823 - val_loss: 0.4077 - val_accuracy: 0.8838 - lr: 5.3144e-05\nEpoch 65/100\n31/31 [==============================] - 13s 425ms/step - loss: 0.0328 - accuracy: 0.9875 - val_loss: 0.4311 - val_accuracy: 0.8797 - lr: 5.3144e-05\nEpoch 66/100\n31/31 [==============================] - 13s 426ms/step - loss: 0.0331 - accuracy: 0.9917 - val_loss: 0.3962 - val_accuracy: 0.8963 - lr: 5.3144e-05\nEpoch 67/100\n31/31 [==============================] - 13s 419ms/step - loss: 0.0252 - accuracy: 0.9907 - val_loss: 0.4932 - val_accuracy: 0.8589 - lr: 5.3144e-05\nEpoch 68/100\n31/31 [==============================] - 13s 424ms/step - loss: 0.0317 - accuracy: 0.9907 - val_loss: 0.4513 - val_accuracy: 0.8755 - lr: 5.3144e-05\nEpoch 69/100\n31/31 [==============================] - 13s 424ms/step - loss: 0.0332 - accuracy: 0.9865 - val_loss: 0.4415 - val_accuracy: 0.8921 - lr: 5.3144e-05\nEpoch 70/100\n31/31 [==============================] - 13s 417ms/step - loss: 0.0328 - accuracy: 0.9896 - val_loss: 0.4286 - val_accuracy: 0.8921 - lr: 5.3144e-05\nEpoch 71/100\n31/31 [==============================] - 13s 428ms/step - loss: 0.0515 - accuracy: 0.9803 - val_loss: 0.4095 - val_accuracy: 0.9129 - lr: 4.7830e-05\nEpoch 72/100\n31/31 [==============================] - 13s 416ms/step - loss: 0.0461 - accuracy: 0.9823 - val_loss: 0.4276 - val_accuracy: 0.8963 - lr: 4.7830e-05\nEpoch 73/100\n31/31 [==============================] - 13s 423ms/step - loss: 0.0481 - accuracy: 0.9782 - val_loss: 0.4534 - val_accuracy: 0.8714 - lr: 4.7830e-05\nEpoch 74/100\n31/31 [==============================] - 13s 418ms/step - loss: 0.0267 - accuracy: 0.9886 - val_loss: 0.4609 - val_accuracy: 0.8714 - lr: 4.7830e-05\nEpoch 75/100\n31/31 [==============================] - 13s 418ms/step - loss: 0.0424 - accuracy: 0.9875 - val_loss: 0.4954 - val_accuracy: 0.8714 - lr: 4.7830e-05\nEpoch 76/100\n31/31 [==============================] - 13s 421ms/step - loss: 0.0788 - accuracy: 0.9751 - val_loss: 0.4458 - val_accuracy: 0.8880 - lr: 4.7830e-05\nEpoch 77/100\n31/31 [==============================] - 13s 417ms/step - loss: 0.0291 - accuracy: 0.9886 - val_loss: 0.4330 - val_accuracy: 0.8921 - lr: 4.7830e-05\nEpoch 78/100\n31/31 [==============================] - 13s 425ms/step - loss: 0.0430 - accuracy: 0.9886 - val_loss: 0.4224 - val_accuracy: 0.9004 - lr: 4.7830e-05\nEpoch 79/100\n31/31 [==============================] - 13s 418ms/step - loss: 0.0275 - accuracy: 0.9938 - val_loss: 0.3886 - val_accuracy: 0.9046 - lr: 4.7830e-05\nEpoch 80/100\n31/31 [==============================] - 13s 418ms/step - loss: 0.0316 - accuracy: 0.9875 - val_loss: 0.4402 - val_accuracy: 0.8963 - lr: 4.7830e-05\nEpoch 81/100\n31/31 [==============================] - 13s 423ms/step - loss: 0.0502 - accuracy: 0.9813 - val_loss: 0.4220 - val_accuracy: 0.8963 - lr: 4.3047e-05\nEpoch 82/100\n31/31 [==============================] - 14s 429ms/step - loss: 0.0375 - accuracy: 0.9896 - val_loss: 0.4420 - val_accuracy: 0.9004 - lr: 4.3047e-05\nEpoch 83/100\n31/31 [==============================] - 14s 431ms/step - loss: 0.0414 - accuracy: 0.9855 - val_loss: 0.4229 - val_accuracy: 0.9046 - lr: 4.3047e-05\nEpoch 84/100\n31/31 [==============================] - 13s 418ms/step - loss: 0.0662 - accuracy: 0.9730 - val_loss: 0.4120 - val_accuracy: 0.9004 - lr: 4.3047e-05\nEpoch 85/100\n31/31 [==============================] - 13s 423ms/step - loss: 0.0358 - accuracy: 0.9896 - val_loss: 0.3778 - val_accuracy: 0.9087 - lr: 4.3047e-05\nEpoch 86/100\n31/31 [==============================] - 13s 421ms/step - loss: 0.0507 - accuracy: 0.9834 - val_loss: 0.4156 - val_accuracy: 0.8963 - lr: 4.3047e-05\nEpoch 87/100\n31/31 [==============================] - 14s 430ms/step - loss: 0.0394 - accuracy: 0.9865 - val_loss: 0.4114 - val_accuracy: 0.9087 - lr: 4.3047e-05\nEpoch 88/100\n31/31 [==============================] - 13s 422ms/step - loss: 0.0300 - accuracy: 0.9907 - val_loss: 0.4148 - val_accuracy: 0.9087 - lr: 4.3047e-05\nEpoch 89/100\n31/31 [==============================] - 13s 423ms/step - loss: 0.0463 - accuracy: 0.9823 - val_loss: 0.4002 - val_accuracy: 0.9046 - lr: 4.3047e-05\nEpoch 90/100\n31/31 [==============================] - 13s 423ms/step - loss: 0.0388 - accuracy: 0.9865 - val_loss: 0.3921 - val_accuracy: 0.9087 - lr: 4.3047e-05\nEpoch 91/100\n31/31 [==============================] - 13s 426ms/step - loss: 0.0487 - accuracy: 0.9792 - val_loss: 0.3817 - val_accuracy: 0.9004 - lr: 3.8742e-05\nEpoch 92/100\n31/31 [==============================] - 13s 421ms/step - loss: 0.0352 - accuracy: 0.9896 - val_loss: 0.4040 - val_accuracy: 0.9004 - lr: 3.8742e-05\nEpoch 93/100\n31/31 [==============================] - 13s 417ms/step - loss: 0.0249 - accuracy: 0.9917 - val_loss: 0.4099 - val_accuracy: 0.8921 - lr: 3.8742e-05\nEpoch 94/100\n31/31 [==============================] - 13s 421ms/step - loss: 0.0304 - accuracy: 0.9907 - val_loss: 0.4227 - val_accuracy: 0.9004 - lr: 3.8742e-05\nEpoch 95/100\n31/31 [==============================] - 13s 422ms/step - loss: 0.0362 - accuracy: 0.9823 - val_loss: 0.4384 - val_accuracy: 0.8921 - lr: 3.8742e-05\nEpoch 96/100\n31/31 [==============================] - 13s 423ms/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.4554 - val_accuracy: 0.8880 - lr: 3.8742e-05\nEpoch 97/100\n31/31 [==============================] - 14s 432ms/step - loss: 0.0435 - accuracy: 0.9875 - val_loss: 0.4209 - val_accuracy: 0.8797 - lr: 3.8742e-05\nEpoch 98/100\n31/31 [==============================] - 13s 417ms/step - loss: 0.0255 - accuracy: 0.9927 - val_loss: 0.4111 - val_accuracy: 0.8921 - lr: 3.8742e-05\nEpoch 99/100\n31/31 [==============================] - 14s 432ms/step - loss: 0.0375 - accuracy: 0.9844 - val_loss: 0.4416 - val_accuracy: 0.8963 - lr: 3.8742e-05\nEpoch 100/100\n31/31 [==============================] - 13s 423ms/step - loss: 0.0438 - accuracy: 0.9823 - val_loss: 0.4498 - val_accuracy: 0.8921 - lr: 3.8742e-05\n8/8 [==============================] - 0s 54ms/step - loss: 0.4498 - accuracy: 0.8921\nValidation Accuracy: 0.8921161890029907\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\npredictions = model.predict(val_data)\nconf_matrix = confusion_matrix(val_labels, predictions > 0.5)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-01-12T11:42:42.828937Z","iopub.execute_input":"2024-01-12T11:42:42.829332Z","iopub.status.idle":"2024-01-12T11:42:43.899838Z","shell.execute_reply.started":"2024-01-12T11:42:42.829300Z","shell.execute_reply":"2024-01-12T11:42:43.898869Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"15/15 [==============================] - 1s 58ms/step\nConfusion Matrix:\n[[247   2]\n [  3 201]]\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save(\"foul_detection_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-01-12T11:42:47.892241Z","iopub.execute_input":"2024-01-12T11:42:47.892626Z","iopub.status.idle":"2024-01-12T11:42:48.768478Z","shell.execute_reply.started":"2024-01-12T11:42:47.892595Z","shell.execute_reply":"2024-01-12T11:42:48.767558Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-12T11:42:53.068756Z","iopub.execute_input":"2024-01-12T11:42:53.069127Z","iopub.status.idle":"2024-01-12T11:42:53.650120Z","shell.execute_reply.started":"2024-01-12T11:42:53.069097Z","shell.execute_reply":"2024-01-12T11:42:53.649154Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_1 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n                                                                                                  \n rescaling (Rescaling)       (None, 224, 224, 3)          0         ['input_1[0][0]']             \n                                                                                                  \n normalization (Normalizati  (None, 224, 224, 3)          7         ['rescaling[0][0]']           \n on)                                                                                              \n                                                                                                  \n rescaling_1 (Rescaling)     (None, 224, 224, 3)          0         ['normalization[0][0]']       \n                                                                                                  \n stem_conv_pad (ZeroPadding  (None, 225, 225, 3)          0         ['rescaling_1[0][0]']         \n 2D)                                                                                              \n                                                                                                  \n stem_conv (Conv2D)          (None, 112, 112, 32)         864       ['stem_conv_pad[0][0]']       \n                                                                                                  \n stem_bn (BatchNormalizatio  (None, 112, 112, 32)         128       ['stem_conv[0][0]']           \n n)                                                                                               \n                                                                                                  \n stem_activation (Activatio  (None, 112, 112, 32)         0         ['stem_bn[0][0]']             \n n)                                                                                               \n                                                                                                  \n block1a_dwconv (DepthwiseC  (None, 112, 112, 32)         288       ['stem_activation[0][0]']     \n onv2D)                                                                                           \n                                                                                                  \n block1a_bn (BatchNormaliza  (None, 112, 112, 32)         128       ['block1a_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block1a_activation (Activa  (None, 112, 112, 32)         0         ['block1a_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block1a_se_squeeze (Global  (None, 32)                   0         ['block1a_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block1a_se_reshape (Reshap  (None, 1, 1, 32)             0         ['block1a_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block1a_se_reduce (Conv2D)  (None, 1, 1, 8)              264       ['block1a_se_reshape[0][0]']  \n                                                                                                  \n block1a_se_expand (Conv2D)  (None, 1, 1, 32)             288       ['block1a_se_reduce[0][0]']   \n                                                                                                  \n block1a_se_excite (Multipl  (None, 112, 112, 32)         0         ['block1a_activation[0][0]',  \n y)                                                                  'block1a_se_expand[0][0]']   \n                                                                                                  \n block1a_project_conv (Conv  (None, 112, 112, 16)         512       ['block1a_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block1a_project_bn (BatchN  (None, 112, 112, 16)         64        ['block1a_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block2a_expand_conv (Conv2  (None, 112, 112, 96)         1536      ['block1a_project_bn[0][0]']  \n D)                                                                                               \n                                                                                                  \n block2a_expand_bn (BatchNo  (None, 112, 112, 96)         384       ['block2a_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block2a_expand_activation   (None, 112, 112, 96)         0         ['block2a_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block2a_dwconv_pad (ZeroPa  (None, 113, 113, 96)         0         ['block2a_expand_activation[0]\n dding2D)                                                           [0]']                         \n                                                                                                  \n block2a_dwconv (DepthwiseC  (None, 56, 56, 96)           864       ['block2a_dwconv_pad[0][0]']  \n onv2D)                                                                                           \n                                                                                                  \n block2a_bn (BatchNormaliza  (None, 56, 56, 96)           384       ['block2a_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block2a_activation (Activa  (None, 56, 56, 96)           0         ['block2a_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block2a_se_squeeze (Global  (None, 96)                   0         ['block2a_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block2a_se_reshape (Reshap  (None, 1, 1, 96)             0         ['block2a_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block2a_se_reduce (Conv2D)  (None, 1, 1, 4)              388       ['block2a_se_reshape[0][0]']  \n                                                                                                  \n block2a_se_expand (Conv2D)  (None, 1, 1, 96)             480       ['block2a_se_reduce[0][0]']   \n                                                                                                  \n block2a_se_excite (Multipl  (None, 56, 56, 96)           0         ['block2a_activation[0][0]',  \n y)                                                                  'block2a_se_expand[0][0]']   \n                                                                                                  \n block2a_project_conv (Conv  (None, 56, 56, 24)           2304      ['block2a_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block2a_project_bn (BatchN  (None, 56, 56, 24)           96        ['block2a_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block2b_expand_conv (Conv2  (None, 56, 56, 144)          3456      ['block2a_project_bn[0][0]']  \n D)                                                                                               \n                                                                                                  \n block2b_expand_bn (BatchNo  (None, 56, 56, 144)          576       ['block2b_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block2b_expand_activation   (None, 56, 56, 144)          0         ['block2b_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block2b_dwconv (DepthwiseC  (None, 56, 56, 144)          1296      ['block2b_expand_activation[0]\n onv2D)                                                             [0]']                         \n                                                                                                  \n block2b_bn (BatchNormaliza  (None, 56, 56, 144)          576       ['block2b_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block2b_activation (Activa  (None, 56, 56, 144)          0         ['block2b_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block2b_se_squeeze (Global  (None, 144)                  0         ['block2b_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block2b_se_reshape (Reshap  (None, 1, 1, 144)            0         ['block2b_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block2b_se_reduce (Conv2D)  (None, 1, 1, 6)              870       ['block2b_se_reshape[0][0]']  \n                                                                                                  \n block2b_se_expand (Conv2D)  (None, 1, 1, 144)            1008      ['block2b_se_reduce[0][0]']   \n                                                                                                  \n block2b_se_excite (Multipl  (None, 56, 56, 144)          0         ['block2b_activation[0][0]',  \n y)                                                                  'block2b_se_expand[0][0]']   \n                                                                                                  \n block2b_project_conv (Conv  (None, 56, 56, 24)           3456      ['block2b_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block2b_project_bn (BatchN  (None, 56, 56, 24)           96        ['block2b_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block2b_drop (Dropout)      (None, 56, 56, 24)           0         ['block2b_project_bn[0][0]']  \n                                                                                                  \n block2b_add (Add)           (None, 56, 56, 24)           0         ['block2b_drop[0][0]',        \n                                                                     'block2a_project_bn[0][0]']  \n                                                                                                  \n block3a_expand_conv (Conv2  (None, 56, 56, 144)          3456      ['block2b_add[0][0]']         \n D)                                                                                               \n                                                                                                  \n block3a_expand_bn (BatchNo  (None, 56, 56, 144)          576       ['block3a_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block3a_expand_activation   (None, 56, 56, 144)          0         ['block3a_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block3a_dwconv_pad (ZeroPa  (None, 59, 59, 144)          0         ['block3a_expand_activation[0]\n dding2D)                                                           [0]']                         \n                                                                                                  \n block3a_dwconv (DepthwiseC  (None, 28, 28, 144)          3600      ['block3a_dwconv_pad[0][0]']  \n onv2D)                                                                                           \n                                                                                                  \n block3a_bn (BatchNormaliza  (None, 28, 28, 144)          576       ['block3a_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block3a_activation (Activa  (None, 28, 28, 144)          0         ['block3a_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block3a_se_squeeze (Global  (None, 144)                  0         ['block3a_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block3a_se_reshape (Reshap  (None, 1, 1, 144)            0         ['block3a_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block3a_se_reduce (Conv2D)  (None, 1, 1, 6)              870       ['block3a_se_reshape[0][0]']  \n                                                                                                  \n block3a_se_expand (Conv2D)  (None, 1, 1, 144)            1008      ['block3a_se_reduce[0][0]']   \n                                                                                                  \n block3a_se_excite (Multipl  (None, 28, 28, 144)          0         ['block3a_activation[0][0]',  \n y)                                                                  'block3a_se_expand[0][0]']   \n                                                                                                  \n block3a_project_conv (Conv  (None, 28, 28, 40)           5760      ['block3a_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block3a_project_bn (BatchN  (None, 28, 28, 40)           160       ['block3a_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block3b_expand_conv (Conv2  (None, 28, 28, 240)          9600      ['block3a_project_bn[0][0]']  \n D)                                                                                               \n                                                                                                  \n block3b_expand_bn (BatchNo  (None, 28, 28, 240)          960       ['block3b_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block3b_expand_activation   (None, 28, 28, 240)          0         ['block3b_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block3b_dwconv (DepthwiseC  (None, 28, 28, 240)          6000      ['block3b_expand_activation[0]\n onv2D)                                                             [0]']                         \n                                                                                                  \n block3b_bn (BatchNormaliza  (None, 28, 28, 240)          960       ['block3b_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block3b_activation (Activa  (None, 28, 28, 240)          0         ['block3b_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block3b_se_squeeze (Global  (None, 240)                  0         ['block3b_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block3b_se_reshape (Reshap  (None, 1, 1, 240)            0         ['block3b_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block3b_se_reduce (Conv2D)  (None, 1, 1, 10)             2410      ['block3b_se_reshape[0][0]']  \n                                                                                                  \n block3b_se_expand (Conv2D)  (None, 1, 1, 240)            2640      ['block3b_se_reduce[0][0]']   \n                                                                                                  \n block3b_se_excite (Multipl  (None, 28, 28, 240)          0         ['block3b_activation[0][0]',  \n y)                                                                  'block3b_se_expand[0][0]']   \n                                                                                                  \n block3b_project_conv (Conv  (None, 28, 28, 40)           9600      ['block3b_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block3b_project_bn (BatchN  (None, 28, 28, 40)           160       ['block3b_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block3b_drop (Dropout)      (None, 28, 28, 40)           0         ['block3b_project_bn[0][0]']  \n                                                                                                  \n block3b_add (Add)           (None, 28, 28, 40)           0         ['block3b_drop[0][0]',        \n                                                                     'block3a_project_bn[0][0]']  \n                                                                                                  \n block4a_expand_conv (Conv2  (None, 28, 28, 240)          9600      ['block3b_add[0][0]']         \n D)                                                                                               \n                                                                                                  \n block4a_expand_bn (BatchNo  (None, 28, 28, 240)          960       ['block4a_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block4a_expand_activation   (None, 28, 28, 240)          0         ['block4a_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block4a_dwconv_pad (ZeroPa  (None, 29, 29, 240)          0         ['block4a_expand_activation[0]\n dding2D)                                                           [0]']                         \n                                                                                                  \n block4a_dwconv (DepthwiseC  (None, 14, 14, 240)          2160      ['block4a_dwconv_pad[0][0]']  \n onv2D)                                                                                           \n                                                                                                  \n block4a_bn (BatchNormaliza  (None, 14, 14, 240)          960       ['block4a_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block4a_activation (Activa  (None, 14, 14, 240)          0         ['block4a_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block4a_se_squeeze (Global  (None, 240)                  0         ['block4a_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block4a_se_reshape (Reshap  (None, 1, 1, 240)            0         ['block4a_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block4a_se_reduce (Conv2D)  (None, 1, 1, 10)             2410      ['block4a_se_reshape[0][0]']  \n                                                                                                  \n block4a_se_expand (Conv2D)  (None, 1, 1, 240)            2640      ['block4a_se_reduce[0][0]']   \n                                                                                                  \n block4a_se_excite (Multipl  (None, 14, 14, 240)          0         ['block4a_activation[0][0]',  \n y)                                                                  'block4a_se_expand[0][0]']   \n                                                                                                  \n block4a_project_conv (Conv  (None, 14, 14, 80)           19200     ['block4a_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block4a_project_bn (BatchN  (None, 14, 14, 80)           320       ['block4a_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block4b_expand_conv (Conv2  (None, 14, 14, 480)          38400     ['block4a_project_bn[0][0]']  \n D)                                                                                               \n                                                                                                  \n block4b_expand_bn (BatchNo  (None, 14, 14, 480)          1920      ['block4b_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block4b_expand_activation   (None, 14, 14, 480)          0         ['block4b_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block4b_dwconv (DepthwiseC  (None, 14, 14, 480)          4320      ['block4b_expand_activation[0]\n onv2D)                                                             [0]']                         \n                                                                                                  \n block4b_bn (BatchNormaliza  (None, 14, 14, 480)          1920      ['block4b_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block4b_activation (Activa  (None, 14, 14, 480)          0         ['block4b_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block4b_se_squeeze (Global  (None, 480)                  0         ['block4b_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block4b_se_reshape (Reshap  (None, 1, 1, 480)            0         ['block4b_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block4b_se_reduce (Conv2D)  (None, 1, 1, 20)             9620      ['block4b_se_reshape[0][0]']  \n                                                                                                  \n block4b_se_expand (Conv2D)  (None, 1, 1, 480)            10080     ['block4b_se_reduce[0][0]']   \n                                                                                                  \n block4b_se_excite (Multipl  (None, 14, 14, 480)          0         ['block4b_activation[0][0]',  \n y)                                                                  'block4b_se_expand[0][0]']   \n                                                                                                  \n block4b_project_conv (Conv  (None, 14, 14, 80)           38400     ['block4b_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block4b_project_bn (BatchN  (None, 14, 14, 80)           320       ['block4b_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block4b_drop (Dropout)      (None, 14, 14, 80)           0         ['block4b_project_bn[0][0]']  \n                                                                                                  \n block4b_add (Add)           (None, 14, 14, 80)           0         ['block4b_drop[0][0]',        \n                                                                     'block4a_project_bn[0][0]']  \n                                                                                                  \n block4c_expand_conv (Conv2  (None, 14, 14, 480)          38400     ['block4b_add[0][0]']         \n D)                                                                                               \n                                                                                                  \n block4c_expand_bn (BatchNo  (None, 14, 14, 480)          1920      ['block4c_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block4c_expand_activation   (None, 14, 14, 480)          0         ['block4c_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block4c_dwconv (DepthwiseC  (None, 14, 14, 480)          4320      ['block4c_expand_activation[0]\n onv2D)                                                             [0]']                         \n                                                                                                  \n block4c_bn (BatchNormaliza  (None, 14, 14, 480)          1920      ['block4c_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block4c_activation (Activa  (None, 14, 14, 480)          0         ['block4c_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block4c_se_squeeze (Global  (None, 480)                  0         ['block4c_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block4c_se_reshape (Reshap  (None, 1, 1, 480)            0         ['block4c_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block4c_se_reduce (Conv2D)  (None, 1, 1, 20)             9620      ['block4c_se_reshape[0][0]']  \n                                                                                                  \n block4c_se_expand (Conv2D)  (None, 1, 1, 480)            10080     ['block4c_se_reduce[0][0]']   \n                                                                                                  \n block4c_se_excite (Multipl  (None, 14, 14, 480)          0         ['block4c_activation[0][0]',  \n y)                                                                  'block4c_se_expand[0][0]']   \n                                                                                                  \n block4c_project_conv (Conv  (None, 14, 14, 80)           38400     ['block4c_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block4c_project_bn (BatchN  (None, 14, 14, 80)           320       ['block4c_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block4c_drop (Dropout)      (None, 14, 14, 80)           0         ['block4c_project_bn[0][0]']  \n                                                                                                  \n block4c_add (Add)           (None, 14, 14, 80)           0         ['block4c_drop[0][0]',        \n                                                                     'block4b_add[0][0]']         \n                                                                                                  \n block5a_expand_conv (Conv2  (None, 14, 14, 480)          38400     ['block4c_add[0][0]']         \n D)                                                                                               \n                                                                                                  \n block5a_expand_bn (BatchNo  (None, 14, 14, 480)          1920      ['block5a_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block5a_expand_activation   (None, 14, 14, 480)          0         ['block5a_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block5a_dwconv (DepthwiseC  (None, 14, 14, 480)          12000     ['block5a_expand_activation[0]\n onv2D)                                                             [0]']                         \n                                                                                                  \n block5a_bn (BatchNormaliza  (None, 14, 14, 480)          1920      ['block5a_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block5a_activation (Activa  (None, 14, 14, 480)          0         ['block5a_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block5a_se_squeeze (Global  (None, 480)                  0         ['block5a_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block5a_se_reshape (Reshap  (None, 1, 1, 480)            0         ['block5a_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block5a_se_reduce (Conv2D)  (None, 1, 1, 20)             9620      ['block5a_se_reshape[0][0]']  \n                                                                                                  \n block5a_se_expand (Conv2D)  (None, 1, 1, 480)            10080     ['block5a_se_reduce[0][0]']   \n                                                                                                  \n block5a_se_excite (Multipl  (None, 14, 14, 480)          0         ['block5a_activation[0][0]',  \n y)                                                                  'block5a_se_expand[0][0]']   \n                                                                                                  \n block5a_project_conv (Conv  (None, 14, 14, 112)          53760     ['block5a_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block5a_project_bn (BatchN  (None, 14, 14, 112)          448       ['block5a_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block5b_expand_conv (Conv2  (None, 14, 14, 672)          75264     ['block5a_project_bn[0][0]']  \n D)                                                                                               \n                                                                                                  \n block5b_expand_bn (BatchNo  (None, 14, 14, 672)          2688      ['block5b_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block5b_expand_activation   (None, 14, 14, 672)          0         ['block5b_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block5b_dwconv (DepthwiseC  (None, 14, 14, 672)          16800     ['block5b_expand_activation[0]\n onv2D)                                                             [0]']                         \n                                                                                                  \n block5b_bn (BatchNormaliza  (None, 14, 14, 672)          2688      ['block5b_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block5b_activation (Activa  (None, 14, 14, 672)          0         ['block5b_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block5b_se_squeeze (Global  (None, 672)                  0         ['block5b_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block5b_se_reshape (Reshap  (None, 1, 1, 672)            0         ['block5b_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block5b_se_reduce (Conv2D)  (None, 1, 1, 28)             18844     ['block5b_se_reshape[0][0]']  \n                                                                                                  \n block5b_se_expand (Conv2D)  (None, 1, 1, 672)            19488     ['block5b_se_reduce[0][0]']   \n                                                                                                  \n block5b_se_excite (Multipl  (None, 14, 14, 672)          0         ['block5b_activation[0][0]',  \n y)                                                                  'block5b_se_expand[0][0]']   \n                                                                                                  \n block5b_project_conv (Conv  (None, 14, 14, 112)          75264     ['block5b_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block5b_project_bn (BatchN  (None, 14, 14, 112)          448       ['block5b_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block5b_drop (Dropout)      (None, 14, 14, 112)          0         ['block5b_project_bn[0][0]']  \n                                                                                                  \n block5b_add (Add)           (None, 14, 14, 112)          0         ['block5b_drop[0][0]',        \n                                                                     'block5a_project_bn[0][0]']  \n                                                                                                  \n block5c_expand_conv (Conv2  (None, 14, 14, 672)          75264     ['block5b_add[0][0]']         \n D)                                                                                               \n                                                                                                  \n block5c_expand_bn (BatchNo  (None, 14, 14, 672)          2688      ['block5c_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block5c_expand_activation   (None, 14, 14, 672)          0         ['block5c_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block5c_dwconv (DepthwiseC  (None, 14, 14, 672)          16800     ['block5c_expand_activation[0]\n onv2D)                                                             [0]']                         \n                                                                                                  \n block5c_bn (BatchNormaliza  (None, 14, 14, 672)          2688      ['block5c_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block5c_activation (Activa  (None, 14, 14, 672)          0         ['block5c_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block5c_se_squeeze (Global  (None, 672)                  0         ['block5c_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block5c_se_reshape (Reshap  (None, 1, 1, 672)            0         ['block5c_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block5c_se_reduce (Conv2D)  (None, 1, 1, 28)             18844     ['block5c_se_reshape[0][0]']  \n                                                                                                  \n block5c_se_expand (Conv2D)  (None, 1, 1, 672)            19488     ['block5c_se_reduce[0][0]']   \n                                                                                                  \n block5c_se_excite (Multipl  (None, 14, 14, 672)          0         ['block5c_activation[0][0]',  \n y)                                                                  'block5c_se_expand[0][0]']   \n                                                                                                  \n block5c_project_conv (Conv  (None, 14, 14, 112)          75264     ['block5c_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block5c_project_bn (BatchN  (None, 14, 14, 112)          448       ['block5c_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block5c_drop (Dropout)      (None, 14, 14, 112)          0         ['block5c_project_bn[0][0]']  \n                                                                                                  \n block5c_add (Add)           (None, 14, 14, 112)          0         ['block5c_drop[0][0]',        \n                                                                     'block5b_add[0][0]']         \n                                                                                                  \n block6a_expand_conv (Conv2  (None, 14, 14, 672)          75264     ['block5c_add[0][0]']         \n D)                                                                                               \n                                                                                                  \n block6a_expand_bn (BatchNo  (None, 14, 14, 672)          2688      ['block6a_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block6a_expand_activation   (None, 14, 14, 672)          0         ['block6a_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block6a_dwconv_pad (ZeroPa  (None, 17, 17, 672)          0         ['block6a_expand_activation[0]\n dding2D)                                                           [0]']                         \n                                                                                                  \n block6a_dwconv (DepthwiseC  (None, 7, 7, 672)            16800     ['block6a_dwconv_pad[0][0]']  \n onv2D)                                                                                           \n                                                                                                  \n block6a_bn (BatchNormaliza  (None, 7, 7, 672)            2688      ['block6a_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block6a_activation (Activa  (None, 7, 7, 672)            0         ['block6a_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block6a_se_squeeze (Global  (None, 672)                  0         ['block6a_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block6a_se_reshape (Reshap  (None, 1, 1, 672)            0         ['block6a_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block6a_se_reduce (Conv2D)  (None, 1, 1, 28)             18844     ['block6a_se_reshape[0][0]']  \n                                                                                                  \n block6a_se_expand (Conv2D)  (None, 1, 1, 672)            19488     ['block6a_se_reduce[0][0]']   \n                                                                                                  \n block6a_se_excite (Multipl  (None, 7, 7, 672)            0         ['block6a_activation[0][0]',  \n y)                                                                  'block6a_se_expand[0][0]']   \n                                                                                                  \n block6a_project_conv (Conv  (None, 7, 7, 192)            129024    ['block6a_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block6a_project_bn (BatchN  (None, 7, 7, 192)            768       ['block6a_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block6b_expand_conv (Conv2  (None, 7, 7, 1152)           221184    ['block6a_project_bn[0][0]']  \n D)                                                                                               \n                                                                                                  \n block6b_expand_bn (BatchNo  (None, 7, 7, 1152)           4608      ['block6b_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block6b_expand_activation   (None, 7, 7, 1152)           0         ['block6b_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block6b_dwconv (DepthwiseC  (None, 7, 7, 1152)           28800     ['block6b_expand_activation[0]\n onv2D)                                                             [0]']                         \n                                                                                                  \n block6b_bn (BatchNormaliza  (None, 7, 7, 1152)           4608      ['block6b_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block6b_activation (Activa  (None, 7, 7, 1152)           0         ['block6b_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block6b_se_squeeze (Global  (None, 1152)                 0         ['block6b_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block6b_se_reshape (Reshap  (None, 1, 1, 1152)           0         ['block6b_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block6b_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     ['block6b_se_reshape[0][0]']  \n                                                                                                  \n block6b_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     ['block6b_se_reduce[0][0]']   \n                                                                                                  \n block6b_se_excite (Multipl  (None, 7, 7, 1152)           0         ['block6b_activation[0][0]',  \n y)                                                                  'block6b_se_expand[0][0]']   \n                                                                                                  \n block6b_project_conv (Conv  (None, 7, 7, 192)            221184    ['block6b_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block6b_project_bn (BatchN  (None, 7, 7, 192)            768       ['block6b_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block6b_drop (Dropout)      (None, 7, 7, 192)            0         ['block6b_project_bn[0][0]']  \n                                                                                                  \n block6b_add (Add)           (None, 7, 7, 192)            0         ['block6b_drop[0][0]',        \n                                                                     'block6a_project_bn[0][0]']  \n                                                                                                  \n block6c_expand_conv (Conv2  (None, 7, 7, 1152)           221184    ['block6b_add[0][0]']         \n D)                                                                                               \n                                                                                                  \n block6c_expand_bn (BatchNo  (None, 7, 7, 1152)           4608      ['block6c_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block6c_expand_activation   (None, 7, 7, 1152)           0         ['block6c_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block6c_dwconv (DepthwiseC  (None, 7, 7, 1152)           28800     ['block6c_expand_activation[0]\n onv2D)                                                             [0]']                         \n                                                                                                  \n block6c_bn (BatchNormaliza  (None, 7, 7, 1152)           4608      ['block6c_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block6c_activation (Activa  (None, 7, 7, 1152)           0         ['block6c_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block6c_se_squeeze (Global  (None, 1152)                 0         ['block6c_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block6c_se_reshape (Reshap  (None, 1, 1, 1152)           0         ['block6c_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block6c_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     ['block6c_se_reshape[0][0]']  \n                                                                                                  \n block6c_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     ['block6c_se_reduce[0][0]']   \n                                                                                                  \n block6c_se_excite (Multipl  (None, 7, 7, 1152)           0         ['block6c_activation[0][0]',  \n y)                                                                  'block6c_se_expand[0][0]']   \n                                                                                                  \n block6c_project_conv (Conv  (None, 7, 7, 192)            221184    ['block6c_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block6c_project_bn (BatchN  (None, 7, 7, 192)            768       ['block6c_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block6c_drop (Dropout)      (None, 7, 7, 192)            0         ['block6c_project_bn[0][0]']  \n                                                                                                  \n block6c_add (Add)           (None, 7, 7, 192)            0         ['block6c_drop[0][0]',        \n                                                                     'block6b_add[0][0]']         \n                                                                                                  \n block6d_expand_conv (Conv2  (None, 7, 7, 1152)           221184    ['block6c_add[0][0]']         \n D)                                                                                               \n                                                                                                  \n block6d_expand_bn (BatchNo  (None, 7, 7, 1152)           4608      ['block6d_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block6d_expand_activation   (None, 7, 7, 1152)           0         ['block6d_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block6d_dwconv (DepthwiseC  (None, 7, 7, 1152)           28800     ['block6d_expand_activation[0]\n onv2D)                                                             [0]']                         \n                                                                                                  \n block6d_bn (BatchNormaliza  (None, 7, 7, 1152)           4608      ['block6d_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block6d_activation (Activa  (None, 7, 7, 1152)           0         ['block6d_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block6d_se_squeeze (Global  (None, 1152)                 0         ['block6d_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block6d_se_reshape (Reshap  (None, 1, 1, 1152)           0         ['block6d_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block6d_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     ['block6d_se_reshape[0][0]']  \n                                                                                                  \n block6d_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     ['block6d_se_reduce[0][0]']   \n                                                                                                  \n block6d_se_excite (Multipl  (None, 7, 7, 1152)           0         ['block6d_activation[0][0]',  \n y)                                                                  'block6d_se_expand[0][0]']   \n                                                                                                  \n block6d_project_conv (Conv  (None, 7, 7, 192)            221184    ['block6d_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block6d_project_bn (BatchN  (None, 7, 7, 192)            768       ['block6d_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n block6d_drop (Dropout)      (None, 7, 7, 192)            0         ['block6d_project_bn[0][0]']  \n                                                                                                  \n block6d_add (Add)           (None, 7, 7, 192)            0         ['block6d_drop[0][0]',        \n                                                                     'block6c_add[0][0]']         \n                                                                                                  \n block7a_expand_conv (Conv2  (None, 7, 7, 1152)           221184    ['block6d_add[0][0]']         \n D)                                                                                               \n                                                                                                  \n block7a_expand_bn (BatchNo  (None, 7, 7, 1152)           4608      ['block7a_expand_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n block7a_expand_activation   (None, 7, 7, 1152)           0         ['block7a_expand_bn[0][0]']   \n (Activation)                                                                                     \n                                                                                                  \n block7a_dwconv (DepthwiseC  (None, 7, 7, 1152)           10368     ['block7a_expand_activation[0]\n onv2D)                                                             [0]']                         \n                                                                                                  \n block7a_bn (BatchNormaliza  (None, 7, 7, 1152)           4608      ['block7a_dwconv[0][0]']      \n tion)                                                                                            \n                                                                                                  \n block7a_activation (Activa  (None, 7, 7, 1152)           0         ['block7a_bn[0][0]']          \n tion)                                                                                            \n                                                                                                  \n block7a_se_squeeze (Global  (None, 1152)                 0         ['block7a_activation[0][0]']  \n AveragePooling2D)                                                                                \n                                                                                                  \n block7a_se_reshape (Reshap  (None, 1, 1, 1152)           0         ['block7a_se_squeeze[0][0]']  \n e)                                                                                               \n                                                                                                  \n block7a_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     ['block7a_se_reshape[0][0]']  \n                                                                                                  \n block7a_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     ['block7a_se_reduce[0][0]']   \n                                                                                                  \n block7a_se_excite (Multipl  (None, 7, 7, 1152)           0         ['block7a_activation[0][0]',  \n y)                                                                  'block7a_se_expand[0][0]']   \n                                                                                                  \n block7a_project_conv (Conv  (None, 7, 7, 320)            368640    ['block7a_se_excite[0][0]']   \n 2D)                                                                                              \n                                                                                                  \n block7a_project_bn (BatchN  (None, 7, 7, 320)            1280      ['block7a_project_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n top_conv (Conv2D)           (None, 7, 7, 1280)           409600    ['block7a_project_bn[0][0]']  \n                                                                                                  \n top_bn (BatchNormalization  (None, 7, 7, 1280)           5120      ['top_conv[0][0]']            \n )                                                                                                \n                                                                                                  \n top_activation (Activation  (None, 7, 7, 1280)           0         ['top_bn[0][0]']              \n )                                                                                                \n                                                                                                  \n global_average_pooling2d (  (None, 1280)                 0         ['top_activation[0][0]']      \n GlobalAveragePooling2D)                                                                          \n                                                                                                  \n dense (Dense)               (None, 512)                  655872    ['global_average_pooling2d[0][\n                                                                    0]']                          \n                                                                                                  \n dropout (Dropout)           (None, 512)                  0         ['dense[0][0]']               \n                                                                                                  \n dense_1 (Dense)             (None, 256)                  131328    ['dropout[0][0]']             \n                                                                                                  \n dropout_1 (Dropout)         (None, 256)                  0         ['dense_1[0][0]']             \n                                                                                                  \n classification (Dense)      (None, 1)                    257       ['dropout_1[0][0]']           \n                                                                                                  \n==================================================================================================\nTotal params: 4837028 (18.45 MB)\nTrainable params: 4795005 (18.29 MB)\nNon-trainable params: 42023 (164.16 KB)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"def detect_foul(image_path, foul_model):\n    img = cv2.imread(image_path)\n    img = cv2.resize(img, (224, 224))  # Resize image to match your model's input size\n    img = np.expand_dims(img, axis=0)  # Add batch dimension\n    prediction = foul_model.predict(img)\n    if prediction >= 0.5:\n        return \"foul\"\n    else:\n        return \"not-foul\"","metadata":{"execution":{"iopub.status.busy":"2024-01-12T11:42:55.647904Z","iopub.execute_input":"2024-01-12T11:42:55.648300Z","iopub.status.idle":"2024-01-12T11:42:55.654332Z","shell.execute_reply.started":"2024-01-12T11:42:55.648267Z","shell.execute_reply":"2024-01-12T11:42:55.653362Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model_path = '/kaggle/working/foul_detection_model.h5'\nfoul_detection_model = tf.keras.models.load_model(model_path)\nimage_path = '/kaggle/input/football-tackles/var500/VAR/Clean_Tackles/109.jpg'\nresult = detect_foul(image_path, foul_detection_model)\nprint(\"Detection Result:\", result)","metadata":{"execution":{"iopub.status.busy":"2024-01-12T11:43:07.947107Z","iopub.execute_input":"2024-01-12T11:43:07.947837Z","iopub.status.idle":"2024-01-12T11:43:13.566518Z","shell.execute_reply.started":"2024-01-12T11:43:07.947804Z","shell.execute_reply":"2024-01-12T11:43:13.565470Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 2s 2s/step\nDetection Result: not-foul\n","output_type":"stream"}]},{"cell_type":"code","source":"model_path = '/kaggle/working/foul_detection_model.h5'\nfoul_detection_model = tf.keras.models.load_model(model_path)\nimage_path = '/kaggle/input/football-tackles/var500/VAR/Fouls/10.jpg'\nresult = detect_foul(image_path, foul_detection_model)\nprint(\"Detection Result:\", result)","metadata":{"execution":{"iopub.status.busy":"2024-01-12T11:43:25.292298Z","iopub.execute_input":"2024-01-12T11:43:25.293172Z","iopub.status.idle":"2024-01-12T11:43:29.923285Z","shell.execute_reply.started":"2024-01-12T11:43:25.293136Z","shell.execute_reply":"2024-01-12T11:43:29.922460Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 2s 2s/step\nDetection Result: foul\n","output_type":"stream"}]},{"cell_type":"code","source":"model_path = '/kaggle/working/foul_detection_model.h5'\nfoul_detection_model = tf.keras.models.load_model(model_path)\nimage_path = '/kaggle/input/football-tackles/var500/VAR/Fouls/108.jpg'\nresult = detect_foul(image_path, foul_detection_model)\nprint(\"Detection Result:\", result)","metadata":{"execution":{"iopub.status.busy":"2024-01-12T11:43:40.840096Z","iopub.execute_input":"2024-01-12T11:43:40.841026Z","iopub.status.idle":"2024-01-12T11:43:45.523945Z","shell.execute_reply.started":"2024-01-12T11:43:40.840989Z","shell.execute_reply":"2024-01-12T11:43:45.523069Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 2s 2s/step\nDetection Result: foul\n","output_type":"stream"}]},{"cell_type":"code","source":"model_path = '/kaggle/working/foul_detection_model.h5'\nfoul_detection_model = tf.keras.models.load_model(model_path)\nimage_path = '/kaggle/input/football-tackles/var500/VAR/Clean_Tackles/111.jpg'\nresult = detect_foul(image_path, foul_detection_model)\nprint(\"Detection Result:\", result)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T06:40:02.258119Z","iopub.execute_input":"2024-01-11T06:40:02.258463Z","iopub.status.idle":"2024-01-11T06:40:07.590081Z","shell.execute_reply.started":"2024-01-11T06:40:02.258434Z","shell.execute_reply":"2024-01-11T06:40:07.589250Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 2s 2s/step\nDetection Result: not-foul\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\ndef process_folder(folder_path, foul_model):\n    foul_counter = 0\n\n    for filename in os.listdir(folder_path):\n        if filename.endswith(('.jpg', '.jpeg', '.png')):  # Add more extensions if needed\n            image_path = os.path.join(folder_path, filename)\n            result = detect_foul(image_path, foul_model)\n\n            if result == \"foul\":\n                foul_counter += 1\n\n    return foul_counter\n\n# Example usage:\nfoul_model_path = '/kaggle/working/foul_detection_model.h5'\nfoul_model = load_model(foul_model_path)\nfolder_path = \"/kaggle/input/op-dataset/OP_Dataset/Test/foul\"\ntotal_fouls = process_folder(folder_path, foul_model)\n\nprint(f\"Total fouls detected: {total_fouls}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-12T11:44:16.203087Z","iopub.execute_input":"2024-01-12T11:44:16.204402Z","iopub.status.idle":"2024-01-12T11:44:53.561553Z","shell.execute_reply.started":"2024-01-12T11:44:16.204353Z","shell.execute_reply":"2024-01-12T11:44:53.560535Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 2s 2s/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 29ms/step\n1/1 [==============================] - 0s 28ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 29ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 28ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 28ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 29ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 34ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 33ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 28ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 30ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 28ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 33ms/step\n1/1 [==============================] - 0s 31ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 28ms/step\n1/1 [==============================] - 0s 42ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 28ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 29ms/step\n1/1 [==============================] - 0s 28ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\nTotal fouls detected: 394\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\ndef process_folder(folder_path, foul_model):\n    foul_counter = 0\n\n    for filename in os.listdir(folder_path):\n        if filename.endswith(('.jpg', '.jpeg', '.png')):  # Add more extensions if needed\n            image_path = os.path.join(folder_path, filename)\n            result = detect_foul(image_path, foul_model)\n\n            if result == \"foul\":\n                foul_counter += 1\n\n    return foul_counter\n\n# Example usage:\nfoul_model_path = '/kaggle/working/foul_detection_model.h5'\nfoul_model = load_model(foul_model_path)\nfolder_path = \"/kaggle/input/op-dataset/OP_Dataset/Test/non_foul\"\ntotal_fouls = process_folder(folder_path, foul_model)\n\nprint(f\"Total fouls detected: {total_fouls}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-12T11:44:57.700665Z","iopub.execute_input":"2024-01-12T11:44:57.701607Z","iopub.status.idle":"2024-01-12T11:45:34.010687Z","shell.execute_reply.started":"2024-01-12T11:44:57.701571Z","shell.execute_reply":"2024-01-12T11:45:34.009684Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 2s 2s/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 33ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 30ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 33ms/step\n1/1 [==============================] - 0s 33ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 28ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 28ms/step\n1/1 [==============================] - 0s 28ms/step\n1/1 [==============================] - 0s 29ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 28ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 28ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 35ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\nTotal fouls detected: 7\n","output_type":"stream"}]},{"cell_type":"code","source":"import wget\nimport os\n\ndef download_model(model_url, save_path):\n    if not os.path.exists(save_path):\n        os.makedirs(save_path)\n\n    model_filename = os.path.join(save_path, 'foul_detection_model.h5')\n\n    if not os.path.exists(model_filename):\n        print(f\"Downloading model from {model_url}\")\n        wget.download(model_url, out=model_filename)\n        print(\"\\nDownload complete.\")\n    else:\n        print(\"Model already exists.\")\n\n    return model_filename\n\n# Example usage:\nmodel_url = 'https://example.com/path/to/foul_detection_model.h5'\nsave_path = '/path/to/save'\n\ndownloaded_model_path = download_model(model_url, save_path)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = '/kaggle/working/foul_detection_model.h5'\nfoul_detection_model = tf.keras.models.load_model(model_path)\nimage_path = '/kaggle/input/soccerdata/dataset/test/foul/209.jpg'\nresult = detect_foul(image_path, foul_detection_model)\nprint(\"Detection Result:\", result)","metadata":{"execution":{"iopub.status.busy":"2024-01-12T12:08:59.935750Z","iopub.execute_input":"2024-01-12T12:08:59.936668Z","iopub.status.idle":"2024-01-12T12:09:04.614892Z","shell.execute_reply.started":"2024-01-12T12:08:59.936633Z","shell.execute_reply":"2024-01-12T12:09:04.613892Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 2s 2s/step\nDetection Result: not-foul\n","output_type":"stream"}]},{"cell_type":"code","source":"model_path = '/kaggle/working/foul_detection_model.h5'\nfoul_detection_model = tf.keras.models.load_model(model_path)\nimage_path = '/kaggle/input/soccerdata/dataset/test/nonfoul/111.jpg'\nresult = detect_foul(image_path, foul_detection_model)\nprint(\"Detection Result:\", result)","metadata":{"execution":{"iopub.status.busy":"2024-01-12T12:00:16.124892Z","iopub.execute_input":"2024-01-12T12:00:16.125322Z","iopub.status.idle":"2024-01-12T12:00:21.680601Z","shell.execute_reply.started":"2024-01-12T12:00:16.125292Z","shell.execute_reply":"2024-01-12T12:00:21.679635Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 2s 2s/step\nDetection Result: not-foul\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\ndef process_folder(folder_path, foul_model):\n    foul_counter = 0\n\n    for filename in os.listdir(folder_path):\n        if filename.endswith(('.jpg', '.jpeg', '.png')):  # Add more extensions if needed\n            image_path = os.path.join(folder_path, filename)\n            result = detect_foul(image_path, foul_model)\n\n            if result == \"foul\":\n                foul_counter += 1\n\n    return foul_counter\n\n# Example usage:\nfoul_model_path = '/kaggle/working/foul_detection_model.h5'\nfoul_model = load_model(foul_model_path)\nfolder_path = \"/kaggle/input/videoframes/kaggle/working/image\"\ntotal_fouls = process_folder(folder_path, foul_model)\n\nprint(f\"Total fouls detected: {total_fouls}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-12T11:58:21.808897Z","iopub.execute_input":"2024-01-12T11:58:21.809785Z","iopub.status.idle":"2024-01-12T11:58:48.318178Z","shell.execute_reply.started":"2024-01-12T11:58:21.809748Z","shell.execute_reply":"2024-01-12T11:58:48.317320Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 1s 1s/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 29ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 28ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 34ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 28ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 29ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 29ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\nTotal fouls detected: 309\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}